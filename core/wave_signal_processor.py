"""
Wave Signal Processor with Smart Duplicate Handling
Implements buffered signal selection with automatic replacement
"""
import logging
from typing import Dict, List, Optional, Set, Union, Any
from datetime import datetime, timezone
from dataclasses import dataclass
import ccxt

logger = logging.getLogger(__name__)


@dataclass
class WaveProcessingStats:
    """Statistics for wave processing"""
    total_signals: int = 0
    signals_with_buffer: int = 0
    duplicates_filtered: int = 0
    buffer_replacements: int = 0
    final_signals: int = 0
    buffer_exhausted: bool = False
    processing_time_ms: float = 0


class WaveSignalProcessor:
    """
    Advanced wave processor with intelligent duplicate replacement.

    Features:
    - Buffer strategy: takes MAX + 33% signals
    - Smart replacement: uses buffer signals when duplicates found
    - Duplicate prevention: one position per symbol
    - Metrics tracking: detailed statistics
    """

    def __init__(self, config, position_manager):
        """
        Initialize wave processor.

        Args:
            config: Trading configuration
            position_manager: Position manager instance
        """
        self.config = config
        self.position_manager = position_manager

        # Wave parameters
        self.max_trades_per_wave = int(getattr(config, 'max_trades_per_15min', 10))
        self.buffer_percent = float(getattr(config, 'signal_buffer_percent', 33))
        self.duplicate_check_enabled = getattr(config, 'duplicate_check_enabled', True)

        # Calculate buffer size
        self.buffer_size = int(self.max_trades_per_wave * (1 + self.buffer_percent / 100))

        # Statistics
        self.wave_stats = {}  # {timestamp: WaveProcessingStats}
        self.total_duplicates_filtered = 0
        self.total_buffer_replacements = 0

        logger.info(
            f"WaveSignalProcessor initialized: "
            f"max_trades={self.max_trades_per_wave}, "
            f"buffer_size={self.buffer_size} (+{self.buffer_percent}%), "
            f"duplicate_check={self.duplicate_check_enabled}"
        )

    async def process_wave_signals(
        self,
        signals: List[Dict],
        wave_timestamp: str = None
    ) -> Dict[str, Any]:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤–æ–ª–Ω—É —Å–∏–≥–Ω–∞–ª–æ–≤ —Å graceful degradation.

        –û–¥–∏–Ω –Ω–µ–≤–µ—Ä–Ω—ã–π —Å–∏–º–≤–æ–ª –ù–ï –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –≤—Å–µ–π –≤–æ–ª–Ω—ã.

        Args:
            signals: –°–ø–∏—Å–æ–∫ —Å–∏–≥–Ω–∞–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            wave_timestamp: Timestamp –≤–æ–ª–Ω—ã

        Returns:
            dict: {
                'successful': [...],
                'failed': [...],
                'skipped': [...],
                'total_signals': int,
                'processed': int,
                'success_rate': float
            }

        Based on: Freqtrade freqtradebot.py process() method
        """
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        successful_signals = []
        failed_signals = []
        skipped_symbols = []

        start_time = datetime.now(timezone.utc)
        wave_id = wave_timestamp or start_time.isoformat()

        logger.info(
            f"üåä Starting wave processing: {len(signals)} signals at "
            f"timestamp {wave_id}"
        )

        # ‚úÖ –ì–õ–ê–í–ù–û–ï –ò–ó–ú–ï–ù–ï–ù–ò–ï: –∏—Å–ø–æ–ª—å–∑—É–µ–º try-except —Å continue
        # Based on: Freqtrade pattern for batch processing
        for idx, signal in enumerate(signals, 1):
            symbol = signal.get('symbol', signal.get('pair_symbol', 'UNKNOWN'))

            try:
                logger.debug(f"Processing signal {idx}/{len(signals)}: {symbol}")

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã
                is_duplicate, reason = await self._is_duplicate(signal, wave_id)

                # ‚úÖ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ–∑–∏—Ü–∏–∏
                # –ï—Å–ª–∏ –≤–µ—Ä–Ω—É–ª—Å—è dict —Å –æ—à–∏–±–∫–æ–π - —Å–∏–º–≤–æ–ª –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π
                if isinstance(is_duplicate, dict) and 'error' in is_duplicate:
                    logger.warning(
                        f"‚ö†Ô∏è Skipping signal {idx} ({symbol}): "
                        f"{is_duplicate['error']} - {is_duplicate['message']}"
                    )
                    failed_signals.append({
                        'signal_number': idx,
                        'symbol': symbol,
                        'error_type': is_duplicate['error'],
                        'message': is_duplicate['message'],
                        'retryable': is_duplicate.get('retryable', False),
                        'signal_data': signal
                    })
                    continue  # ‚úÖ –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å–æ —Å–ª–µ–¥—É—é—â–∏–º —Å–∏–≥–Ω–∞–ª–æ–º

                # –ï—Å–ª–∏ –¥—É–±–ª–∏–∫–∞—Ç - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                if is_duplicate:
                    logger.info(f"‚è≠Ô∏è Signal {idx} ({symbol}) is duplicate: {reason}")
                    skipped_symbols.append({
                        'symbol': symbol,
                        'reason': reason
                    })
                    continue  # ‚úÖ –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å–æ —Å–ª–µ–¥—É—é—â–∏–º —Å–∏–≥–Ω–∞–ª–æ–º

                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–∏–≥–Ω–∞–ª
                result = await self._process_single_signal(signal, wave_id)

                if result:
                    successful_signals.append({
                        'signal_number': idx,
                        'symbol': symbol,
                        'result': result,
                        'signal_data': signal  # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Å–∏–≥–Ω–∞–ª –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è
                    })
                    logger.info(f"‚úÖ Signal {idx} ({symbol}) processed successfully")
                else:
                    logger.warning(f"‚ö†Ô∏è Signal {idx} ({symbol}) processing returned None")
                    failed_signals.append({
                        'signal_number': idx,
                        'symbol': symbol,
                        'error_type': 'processing_failed',
                        'message': 'Processing returned None/False',
                        'retryable': False
                    })

            except ccxt.BadSymbol as e:
                # –ù–µ –¥–æ–ª–∂–Ω–æ –ø–æ–ø–∞—Å—Ç—å —Å—é–¥–∞ (–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è –≤ position_manager)
                # –Ω–æ –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π –ª–æ–≤–∏–º
                logger.error(f"‚ùå BadSymbol leaked to processor for {symbol}: {e}")
                failed_signals.append({
                    'signal_number': idx,
                    'symbol': symbol,
                    'error_type': 'bad_symbol_leaked',
                    'message': str(e),
                    'retryable': False
                })
                continue  # ‚úÖ –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å –æ—Å—Ç–∞–ª—å–Ω—ã–º–∏

            except ccxt.InsufficientFunds as e:
                # –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å—Ä–µ–¥—Å—Ç–≤ - –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤–µ—Å—å batch
                logger.error(f"üí∞ Insufficient funds at signal {idx} ({symbol}): {e}")
                failed_signals.append({
                    'signal_number': idx,
                    'symbol': symbol,
                    'error_type': 'insufficient_funds',
                    'message': str(e),
                    'retryable': False
                })
                break  # ‚ùå –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º - —Å—Ä–µ–¥—Å—Ç–≤–∞ –∫–æ–Ω—á–∏–ª–∏—Å—å

            except Exception as e:
                # –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ –æ—à–∏–±–∫–∏ - –ª–æ–≥–∏—Ä—É–µ–º –∏ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º
                logger.error(
                    f"‚ùå Unexpected error processing signal {idx} ({symbol}): {e}",
                    exc_info=True
                )
                failed_signals.append({
                    'signal_number': idx,
                    'symbol': symbol,
                    'error_type': 'unexpected_error',
                    'message': str(e),
                    'retryable': False
                })
                continue  # ‚úÖ –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å –æ—Å—Ç–∞–ª—å–Ω—ã–º–∏ —Å–∏–≥–Ω–∞–ª–∞–º–∏

        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        result = {
            'successful': successful_signals,
            'failed': failed_signals,
            'skipped': skipped_symbols,
            'total_signals': len(signals),
            'processed': len(successful_signals),
            'failed_count': len(failed_signals),
            'skipped_count': len(skipped_symbols),
            'success_rate': len(successful_signals) / len(signals) if signals else 0
        }

        # –î–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        processing_time = (datetime.now(timezone.utc) - start_time).total_seconds() * 1000
        logger.info(
            f"üåä Wave processing complete in {processing_time:.0f}ms: "
            f"‚úÖ {result['processed']} successful, "
            f"‚ùå {result['failed_count']} failed, "
            f"‚è≠Ô∏è {result['skipped_count']} skipped, "
            f"üìä Success rate: {result['success_rate']:.1%}"
        )

        # –õ–æ–≥–∏—Ä—É–µ–º –¥–µ—Ç–∞–ª–∏ –Ω–µ—É–¥–∞—á–Ω—ã—Ö
        if failed_signals:
            logger.warning(f"Failed signals breakdown:")
            for failed in failed_signals:
                logger.warning(
                    f"  - Signal #{failed['signal_number']} ({failed['symbol']}): "
                    f"{failed['error_type']} - {failed['message']}"
                )

        return result

    async def _is_duplicate(self, signal: Dict, wave_timestamp: str) -> tuple:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å–∏–≥–Ω–∞–ª –¥—É–±–ª–∏–∫–∞—Ç–æ–º.

        Returns:
            tuple: (is_duplicate: Union[bool, dict], reason: str)
                - –ï—Å–ª–∏ bool: True/False - —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏
                - –ï—Å–ª–∏ dict: error object —Å –¥–µ—Ç–∞–ª—è–º–∏ –æ—à–∏–±–∫–∏
        """
        symbol = signal.get('symbol', signal.get('pair_symbol', ''))
        # –ö–†–ò–¢–ò–ß–ù–û: –ò–∑–≤–ª–µ–∫–∞–µ–º –±–∏—Ä–∂—É –∏–∑ —Å–∏–≥–Ω–∞–ª–∞!
        exchange = signal.get('exchange', signal.get('exchange_name', ''))

        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ—Ç–∫—Ä—ã—Ç–æ–π –ø–æ–∑–∏—Ü–∏–∏ –ù–ê –ö–û–ù–ö–†–ï–¢–ù–û–ô –ë–ò–†–ñ–ï
            if exchange:
                has_position = await self.position_manager.has_open_position(symbol, exchange)
            else:
                # –ï—Å–ª–∏ –±–∏—Ä–∂–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞ - –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –≤—Å–µ—Ö (–¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
                logger.warning(f"Exchange not specified for signal {symbol}, checking all exchanges")
                has_position = await self.position_manager.has_open_position(symbol)

            # ‚úÖ –ö–†–ò–¢–ò–ß–ù–û: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º error object
            if isinstance(has_position, dict) and 'error' in has_position:
                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º error object –Ω–∞–≤–µ—Ä—Ö
                return has_position, ""

            # –ï—Å–ª–∏ –ø–æ–∑–∏—Ü–∏—è –µ—Å—Ç—å - —ç—Ç–æ –¥—É–±–ª–∏–∫–∞—Ç
            if has_position:
                return True, "Position already exists"

            # ... –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ ...

            return False, ""

        except Exception as e:
            logger.error(f"Error in _is_duplicate for {symbol}: {e}", exc_info=True)
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º error object
            return {
                'error': 'duplicate_check_failed',
                'symbol': symbol,
                'message': str(e),
                'retryable': False
            }, ""

    async def _process_single_signal(self, signal: Dict, wave_timestamp: str) -> Optional[Dict]:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–∏–Ω —Å–∏–≥–Ω–∞–ª.

        Args:
            signal: –°–∏–≥–Ω–∞–ª –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            wave_timestamp: Timestamp –≤–æ–ª–Ω—ã

        Returns:
            Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–ª–∏ None –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å
        """
        try:
            # FIX: 2025-10-03 - CRITICAL: Modify original signal to ensure SignalProcessor gets correct action
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç—É –∂–µ –ª–æ–≥–∏–∫—É —á—Ç–æ –≤ SignalProcessor (signal_type –∏–ª–∏ recommended_action)
            action = signal.get('signal_type') or signal.get('recommended_action') or signal.get('action')

            # CRITICAL FIX: Modify the original signal so SignalProcessor gets the correct action
            if action and not signal.get('action'):
                signal['action'] = action
                logger.debug(f"Signal #{signal.get('id', 'unknown')} action set to: {action}")

            # Also ensure signal_type is set for SignalProcessor validation
            if action and not signal.get('signal_type'):
                signal['signal_type'] = action

            # Return processing result
            return {
                'symbol': signal.get('symbol', signal.get('pair_symbol', '')),
                'action': action,
                'processed_at': wave_timestamp,
                'status': 'processed'
            }
        except Exception as e:
            logger.error(f"Error processing single signal: {e}", exc_info=True)
            return None

    async def _get_open_positions(self) -> List[Dict]:
        """Get all open positions with details."""

        try:
            # Get from position manager
            positions = []

            # Check local tracking
            for symbol, position_state in self.position_manager.positions.items():
                positions.append({
                    'symbol': symbol,
                    'side': position_state.side,
                    'exchange': position_state.exchange,
                    'entry_price': position_state.entry_price,
                    'quantity': position_state.quantity,
                    'status': 'open'
                })

            return positions

        except Exception as e:
            logger.error(f"Error getting open positions: {e}")
            return []

    def get_statistics(self) -> Dict:
        """Get processing statistics."""

        recent_waves = list(self.wave_stats.items())[-10:]  # Last 10 waves

        if recent_waves:
            avg_duplicates = sum(s.duplicates_filtered for _, s in recent_waves) / len(recent_waves)
            avg_replacements = sum(s.buffer_replacements for _, s in recent_waves) / len(recent_waves)
            buffer_exhausted_count = sum(1 for _, s in recent_waves if s.buffer_exhausted)
        else:
            avg_duplicates = 0
            avg_replacements = 0
            buffer_exhausted_count = 0

        return {
            'buffer_config': {
                'max_trades_per_wave': self.max_trades_per_wave,
                'buffer_percent': self.buffer_percent,
                'buffer_size': self.buffer_size
            },
            'total_stats': {
                'duplicates_filtered': self.total_duplicates_filtered,
                'buffer_replacements': self.total_buffer_replacements,
                'waves_processed': len(self.wave_stats)
            },
            'recent_stats': {
                'avg_duplicates_per_wave': avg_duplicates,
                'avg_replacements_per_wave': avg_replacements,
                'buffer_exhausted_count': buffer_exhausted_count,
                'sample_size': len(recent_waves)
            }
        }

    def reset_statistics(self):
        """Reset all statistics."""
        self.wave_stats.clear()
        self.total_duplicates_filtered = 0
        self.total_buffer_replacements = 0
        logger.info("Wave processor statistics reset")