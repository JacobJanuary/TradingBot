"""
Wave Signal Processor with Smart Duplicate Handling
Implements buffered signal selection with automatic replacement
"""
import logging
from typing import Dict, List, Optional, Set, Union, Any
from datetime import datetime, timezone
from dataclasses import dataclass
import ccxt

logger = logging.getLogger(__name__)


@dataclass
class WaveProcessingStats:
    """Statistics for wave processing"""
    total_signals: int = 0
    signals_with_buffer: int = 0
    duplicates_filtered: int = 0
    buffer_replacements: int = 0
    final_signals: int = 0
    buffer_exhausted: bool = False
    processing_time_ms: float = 0


class WaveSignalProcessor:
    """
    Advanced wave processor with intelligent duplicate replacement.

    Features:
    - Buffer strategy: takes MAX + 33% signals
    - Smart replacement: uses buffer signals when duplicates found
    - Duplicate prevention: one position per symbol
    - Metrics tracking: detailed statistics
    """

    def __init__(self, config, position_manager):
        """
        Initialize wave processor.

        Args:
            config: Trading configuration
            position_manager: Position manager instance
        """
        self.config = config
        self.position_manager = position_manager

        # Wave parameters
        self.max_trades_per_wave = int(getattr(config, 'max_trades_per_15min', 10))
        self.buffer_percent = float(getattr(config, 'signal_buffer_percent', 33))
        self.duplicate_check_enabled = getattr(config, 'duplicate_check_enabled', True)

        # Calculate buffer size
        self.buffer_size = int(self.max_trades_per_wave * (1 + self.buffer_percent / 100))

        # Statistics
        self.wave_stats = {}  # {timestamp: WaveProcessingStats}
        self.total_duplicates_filtered = 0
        self.total_buffer_replacements = 0

        logger.info(
            f"WaveSignalProcessor initialized: "
            f"max_trades={self.max_trades_per_wave}, "
            f"buffer_size={self.buffer_size} (+{self.buffer_percent}%), "
            f"duplicate_check={self.duplicate_check_enabled}"
        )

    async def process_wave_signals(
        self,
        signals: List[Dict],
        wave_timestamp: str = None
    ) -> Dict[str, Any]:
        """
        ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ Ð²Ð¾Ð»Ð½Ñƒ ÑÐ¸Ð³Ð½Ð°Ð»Ð¾Ð² Ñ graceful degradation.

        ÐžÐ´Ð¸Ð½ Ð½ÐµÐ²ÐµÑ€Ð½Ñ‹Ð¹ ÑÐ¸Ð¼Ð²Ð¾Ð» ÐÐ• Ð¾ÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÑ‚ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÑƒ Ð²ÑÐµÐ¹ Ð²Ð¾Ð»Ð½Ñ‹.

        Args:
            signals: Ð¡Ð¿Ð¸ÑÐ¾Ðº ÑÐ¸Ð³Ð½Ð°Ð»Ð¾Ð² Ð´Ð»Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸
            wave_timestamp: Timestamp Ð²Ð¾Ð»Ð½Ñ‹

        Returns:
            dict: {
                'successful': [...],
                'failed': [...],
                'skipped': [...],
                'total_signals': int,
                'processed': int,
                'success_rate': float
            }

        Based on: Freqtrade freqtradebot.py process() method
        """
        # Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²
        successful_signals = []
        failed_signals = []
        skipped_symbols = []

        start_time = datetime.now(timezone.utc)
        wave_id = wave_timestamp or start_time.isoformat()

        logger.info(
            f"ðŸŒŠ Starting wave processing: {len(signals)} signals at "
            f"timestamp {wave_id}"
        )

        # âœ… Ð“Ð›ÐÐ’ÐÐžÐ• Ð˜Ð—ÐœÐ•ÐÐ•ÐÐ˜Ð•: Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ try-except Ñ continue
        # Based on: Freqtrade pattern for batch processing
        for idx, signal in enumerate(signals, 1):
            symbol = signal.get('symbol', signal.get('pair_symbol', 'UNKNOWN'))

            try:
                logger.debug(f"Processing signal {idx}/{len(signals)}: {symbol}")

                # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð½Ð° Ð´ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ‚Ñ‹
                is_duplicate, reason = await self._is_duplicate(signal, wave_id)

                # âœ… ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸ Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ð¸
                # Ð•ÑÐ»Ð¸ Ð²ÐµÑ€Ð½ÑƒÐ»ÑÑ dict Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ¾Ð¹ - ÑÐ¸Ð¼Ð²Ð¾Ð» Ð½ÐµÐ²Ð°Ð»Ð¸Ð´Ð½Ñ‹Ð¹
                if isinstance(is_duplicate, dict) and 'error' in is_duplicate:
                    logger.warning(
                        f"âš ï¸ Skipping signal {idx} ({symbol}): "
                        f"{is_duplicate['error']} - {is_duplicate['message']}"
                    )
                    failed_signals.append({
                        'signal_number': idx,
                        'symbol': symbol,
                        'error_type': is_duplicate['error'],
                        'message': is_duplicate['message'],
                        'retryable': is_duplicate.get('retryable', False),
                        'signal_data': signal
                    })
                    continue  # âœ… ÐŸÑ€Ð¾Ð´Ð¾Ð»Ð¶Ð°ÐµÐ¼ ÑÐ¾ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰Ð¸Ð¼ ÑÐ¸Ð³Ð½Ð°Ð»Ð¾Ð¼

                # Ð•ÑÐ»Ð¸ Ð´ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ‚ - Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÐ°ÐµÐ¼
                if is_duplicate:
                    logger.info(f"â­ï¸ Signal {idx} ({symbol}) is duplicate: {reason}")
                    skipped_symbols.append({
                        'symbol': symbol,
                        'reason': reason
                    })
                    continue  # âœ… ÐŸÑ€Ð¾Ð´Ð¾Ð»Ð¶Ð°ÐµÐ¼ ÑÐ¾ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰Ð¸Ð¼ ÑÐ¸Ð³Ð½Ð°Ð»Ð¾Ð¼

                # ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ ÑÐ¸Ð³Ð½Ð°Ð»
                result = await self._process_single_signal(signal, wave_id)

                if result:
                    successful_signals.append({
                        'signal_number': idx,
                        'symbol': symbol,
                        'result': result,
                        'signal_data': signal  # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ ÑÐ¸Ð³Ð½Ð°Ð» Ð´Ð»Ñ Ð¿Ð¾ÑÐ»ÐµÐ´ÑƒÑŽÑ‰ÐµÐ³Ð¾ Ð¸ÑÐ¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ñ
                    })
                    logger.info(f"âœ… Signal {idx} ({symbol}) processed successfully")
                else:
                    logger.warning(f"âš ï¸ Signal {idx} ({symbol}) processing returned None")
                    failed_signals.append({
                        'signal_number': idx,
                        'symbol': symbol,
                        'error_type': 'processing_failed',
                        'message': 'Processing returned None/False',
                        'retryable': False
                    })

            except ccxt.BadSymbol as e:
                # ÐÐµ Ð´Ð¾Ð»Ð¶Ð½Ð¾ Ð¿Ð¾Ð¿Ð°ÑÑ‚ÑŒ ÑÑŽÐ´Ð° (Ð¾Ð±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ÑÑ Ð² position_manager)
                # Ð½Ð¾ Ð½Ð° Ð²ÑÑÐºÐ¸Ð¹ ÑÐ»ÑƒÑ‡Ð°Ð¹ Ð»Ð¾Ð²Ð¸Ð¼
                logger.error(f"âŒ BadSymbol leaked to processor for {symbol}: {e}")
                failed_signals.append({
                    'signal_number': idx,
                    'symbol': symbol,
                    'error_type': 'bad_symbol_leaked',
                    'message': str(e),
                    'retryable': False
                })
                continue  # âœ… ÐŸÑ€Ð¾Ð´Ð¾Ð»Ð¶Ð°ÐµÐ¼ Ñ Ð¾ÑÑ‚Ð°Ð»ÑŒÐ½Ñ‹Ð¼Ð¸

            except ccxt.InsufficientFunds as e:
                # ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ ÑÑ€ÐµÐ´ÑÑ‚Ð² - Ð¾ÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð²ÐµÑÑŒ batch
                logger.error(f"ðŸ’° Insufficient funds at signal {idx} ({symbol}): {e}")
                failed_signals.append({
                    'signal_number': idx,
                    'symbol': symbol,
                    'error_type': 'insufficient_funds',
                    'message': str(e),
                    'retryable': False
                })
                break  # âŒ ÐžÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ - ÑÑ€ÐµÐ´ÑÑ‚Ð²Ð° ÐºÐ¾Ð½Ñ‡Ð¸Ð»Ð¸ÑÑŒ

            except Exception as e:
                # ÐÐµÐ¾Ð¶Ð¸Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¾ÑˆÐ¸Ð±ÐºÐ¸ - Ð»Ð¾Ð³Ð¸Ñ€ÑƒÐµÐ¼ Ð¸ Ð¿Ñ€Ð¾Ð´Ð¾Ð»Ð¶Ð°ÐµÐ¼
                logger.error(
                    f"âŒ Unexpected error processing signal {idx} ({symbol}): {e}",
                    exc_info=True
                )
                failed_signals.append({
                    'signal_number': idx,
                    'symbol': symbol,
                    'error_type': 'unexpected_error',
                    'message': str(e),
                    'retryable': False
                })
                continue  # âœ… ÐŸÑ€Ð¾Ð´Ð¾Ð»Ð¶Ð°ÐµÐ¼ Ñ Ð¾ÑÑ‚Ð°Ð»ÑŒÐ½Ñ‹Ð¼Ð¸ ÑÐ¸Ð³Ð½Ð°Ð»Ð°Ð¼Ð¸

        # Ð¤Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐµÐ¼ Ð¸Ñ‚Ð¾Ð³Ð¾Ð²Ñ‹Ð¹ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚
        result = {
            'successful': successful_signals,
            'failed': failed_signals,
            'skipped': skipped_symbols,
            'total_signals': len(signals),
            'processed': len(successful_signals),
            'failed_count': len(failed_signals),
            'skipped_count': len(skipped_symbols),
            'success_rate': len(successful_signals) / len(signals) if signals else 0
        }

        # Ð”ÐµÑ‚Ð°Ð»ÑŒÐ½Ð¾Ðµ Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²
        processing_time = (datetime.now(timezone.utc) - start_time).total_seconds() * 1000
        logger.info(
            f"ðŸŒŠ Wave processing complete in {processing_time:.0f}ms: "
            f"âœ… {result['processed']} successful, "
            f"âŒ {result['failed_count']} failed, "
            f"â­ï¸ {result['skipped_count']} skipped, "
            f"ðŸ“Š Success rate: {result['success_rate']:.1%}"
        )

        # Ð›Ð¾Ð³Ð¸Ñ€ÑƒÐµÐ¼ Ð´ÐµÑ‚Ð°Ð»Ð¸ Ð½ÐµÑƒÐ´Ð°Ñ‡Ð½Ñ‹Ñ…
        if failed_signals:
            logger.warning(f"Failed signals breakdown:")
            for failed in failed_signals:
                logger.warning(
                    f"  - Signal #{failed['signal_number']} ({failed['symbol']}): "
                    f"{failed['error_type']} - {failed['message']}"
                )

        return result

    async def _is_duplicate(self, signal: Dict, wave_timestamp: str) -> tuple:
        """
        ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÑ‚ ÑÐ²Ð»ÑÐµÑ‚ÑÑ Ð»Ð¸ ÑÐ¸Ð³Ð½Ð°Ð» Ð´ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ‚Ð¾Ð¼.

        Returns:
            tuple: (is_duplicate: Union[bool, dict], reason: str)
                - Ð•ÑÐ»Ð¸ bool: True/False - Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸
                - Ð•ÑÐ»Ð¸ dict: error object Ñ Ð´ÐµÑ‚Ð°Ð»ÑÐ¼Ð¸ Ð¾ÑˆÐ¸Ð±ÐºÐ¸
        """
        symbol = signal.get('symbol', signal.get('pair_symbol', ''))
        # ÐšÐ Ð˜Ð¢Ð˜Ð§ÐÐž: Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ Ð±Ð¸Ñ€Ð¶Ñƒ Ð¸Ð· ÑÐ¸Ð³Ð½Ð°Ð»Ð°!
        exchange = signal.get('exchange', signal.get('exchange_name', ''))

        try:
            # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð½Ð°Ð»Ð¸Ñ‡Ð¸Ðµ Ð¾Ñ‚ÐºÑ€Ñ‹Ñ‚Ð¾Ð¹ Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ð¸ ÐÐ ÐšÐžÐÐšÐ Ð•Ð¢ÐÐžÐ™ Ð‘Ð˜Ð Ð–Ð•
            if exchange:
                has_position = await self.position_manager.has_open_position(symbol, exchange)
            else:
                # Ð•ÑÐ»Ð¸ Ð±Ð¸Ñ€Ð¶Ð° Ð½Ðµ ÑƒÐºÐ°Ð·Ð°Ð½Ð° - Ð¿Ñ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð½Ð° Ð²ÑÐµÑ… (Ð´Ð»Ñ Ð¾Ð±Ñ€Ð°Ñ‚Ð½Ð¾Ð¹ ÑÐ¾Ð²Ð¼ÐµÑÑ‚Ð¸Ð¼Ð¾ÑÑ‚Ð¸)
                logger.warning(f"Exchange not specified for signal {symbol}, checking all exchanges")
                has_position = await self.position_manager.has_open_position(symbol)

            # âœ… ÐšÐ Ð˜Ð¢Ð˜Ð§ÐÐž: ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ error object
            if isinstance(has_position, dict) and 'error' in has_position:
                # Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÐ¼ error object Ð½Ð°Ð²ÐµÑ€Ñ…
                return has_position, ""

            # Ð•ÑÐ»Ð¸ Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ñ ÐµÑÑ‚ÑŒ - ÑÑ‚Ð¾ Ð´ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ‚
            if has_position:
                return True, "Position already exists"

            # ... Ð¾ÑÑ‚Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸ Ð´ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ‚Ð¾Ð² ...

            return False, ""

        except Exception as e:
            logger.error(f"Error in _is_duplicate for {symbol}: {e}", exc_info=True)
            # Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÐ¼ error object
            return {
                'error': 'duplicate_check_failed',
                'symbol': symbol,
                'message': str(e),
                'retryable': False
            }, ""

    async def _process_single_signal(self, signal: Dict, wave_timestamp: str) -> Optional[Dict]:
        """
        ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ Ð¾Ð´Ð¸Ð½ ÑÐ¸Ð³Ð½Ð°Ð».

        Args:
            signal: Ð¡Ð¸Ð³Ð½Ð°Ð» Ð´Ð»Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸
            wave_timestamp: Timestamp Ð²Ð¾Ð»Ð½Ñ‹

        Returns:
            Dict Ñ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð¼ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð¸Ð»Ð¸ None ÐµÑÐ»Ð¸ Ð½Ðµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ
        """
        try:
            # FIX: 2025-10-03 - CRITICAL: Modify original signal to ensure SignalProcessor gets correct action
            # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ñ‚Ñƒ Ð¶Ðµ Ð»Ð¾Ð³Ð¸ÐºÑƒ Ñ‡Ñ‚Ð¾ Ð² SignalProcessor (signal_type Ð¸Ð»Ð¸ recommended_action)
            action = signal.get('signal_type') or signal.get('recommended_action') or signal.get('action')

            # CRITICAL FIX: Modify the original signal so SignalProcessor gets the correct action
            if action and not signal.get('action'):
                signal['action'] = action
                logger.debug(f"Signal #{signal.get('id', 'unknown')} action set to: {action}")

            # Also ensure signal_type is set for SignalProcessor validation
            if action and not signal.get('signal_type'):
                signal['signal_type'] = action

            # Return processing result
            return {
                'symbol': signal.get('symbol', signal.get('pair_symbol', '')),
                'action': action,
                'processed_at': wave_timestamp,
                'status': 'processed'
            }
        except Exception as e:
            logger.error(f"Error processing single signal: {e}", exc_info=True)
            return None

    async def _get_open_positions(self) -> List[Dict]:
        """Get all open positions with details."""

        try:
            # Get from position manager
            positions = []

            # Check local tracking
            for symbol, position_state in self.position_manager.positions.items():
                positions.append({
                    'symbol': symbol,
                    'side': position_state.side,
                    'exchange': position_state.exchange,
                    'entry_price': position_state.entry_price,
                    'quantity': position_state.quantity,
                    'status': 'open'
                })

            return positions

        except Exception as e:
            logger.error(f"Error getting open positions: {e}")
            return []

    def get_statistics(self) -> Dict:
        """Get processing statistics."""

        recent_waves = list(self.wave_stats.items())[-10:]  # Last 10 waves

        if recent_waves:
            avg_duplicates = sum(s.duplicates_filtered for _, s in recent_waves) / len(recent_waves)
            avg_replacements = sum(s.buffer_replacements for _, s in recent_waves) / len(recent_waves)
            buffer_exhausted_count = sum(1 for _, s in recent_waves if s.buffer_exhausted)
        else:
            avg_duplicates = 0
            avg_replacements = 0
            buffer_exhausted_count = 0

        return {
            'buffer_config': {
                'max_trades_per_wave': self.max_trades_per_wave,
                'buffer_percent': self.buffer_percent,
                'buffer_size': self.buffer_size
            },
            'total_stats': {
                'duplicates_filtered': self.total_duplicates_filtered,
                'buffer_replacements': self.total_buffer_replacements,
                'waves_processed': len(self.wave_stats)
            },
            'recent_stats': {
                'avg_duplicates_per_wave': avg_duplicates,
                'avg_replacements_per_wave': avg_replacements,
                'buffer_exhausted_count': buffer_exhausted_count,
                'sample_size': len(recent_waves)
            }
        }

    def reset_statistics(self):
        """Reset all statistics."""
        self.wave_stats.clear()
        self.total_duplicates_filtered = 0
        self.total_buffer_replacements = 0
        logger.info("Wave processor statistics reset")